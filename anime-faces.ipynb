{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Importing Modules**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:00.810237Z","iopub.status.busy":"2024-04-23T08:37:00.809728Z","iopub.status.idle":"2024-04-23T08:37:00.818657Z","shell.execute_reply":"2024-04-23T08:37:00.817047Z","shell.execute_reply.started":"2024-04-23T08:37:00.810178Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'numpy'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"]}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","from tqdm.notebook import tqdm\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import load_img, array_to_img\n","from tensorflow.keras.models import Sequential , Model\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import BinaryCrossentropy\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["**Load files**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:00.821094Z","iopub.status.busy":"2024-04-23T08:37:00.820695Z","iopub.status.idle":"2024-04-23T08:37:00.837274Z","shell.execute_reply":"2024-04-23T08:37:00.836253Z","shell.execute_reply.started":"2024-04-23T08:37:00.821064Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = '/kaggle/input/anime-faces/data'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:00.839784Z","iopub.status.busy":"2024-04-23T08:37:00.839173Z","iopub.status.idle":"2024-04-23T08:37:00.914797Z","shell.execute_reply":"2024-04-23T08:37:00.913389Z","shell.execute_reply.started":"2024-04-23T08:37:00.839754Z"},"trusted":true},"outputs":[],"source":["#load all image files to a list\n","image_paths =[]\n","for image_name in os.listdir(BASE_DIR):\n","    image_path = os.path.join(BASE_DIR, image_name)\n","    image_paths.append(image_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:00.916874Z","iopub.status.busy":"2024-04-23T08:37:00.916490Z","iopub.status.idle":"2024-04-23T08:37:00.923610Z","shell.execute_reply":"2024-04-23T08:37:00.922015Z","shell.execute_reply.started":"2024-04-23T08:37:00.916843Z"},"trusted":true},"outputs":[],"source":["image_paths.remove('/kaggle/input/anime-faces/data/data')"]},{"cell_type":"markdown","metadata":{},"source":["**Visializing Image Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:00.927879Z","iopub.status.busy":"2024-04-23T08:37:00.927200Z","iopub.status.idle":"2024-04-23T08:37:04.780658Z","shell.execute_reply":"2024-04-23T08:37:04.777743Z","shell.execute_reply.started":"2024-04-23T08:37:00.927844Z"},"trusted":true},"outputs":[],"source":["#displaying a grid of images\n","plt.figure(figsize=(20,20))\n","temp_images = image_paths[:49] #grid of 7X7 images\n","index=1\n","for image_path in temp_images :\n","    plt.subplot(7,7,index)\n","    #load the image\n","    img = load_img(image_path)\n","    #convert to numpy array\n","    img = np.array(img)\n","\n","    #display the image\n","    plt.imshow(img)\n","    plt.axis('off')\n","    #increment the index to load next image\n","    index +=1"]},{"cell_type":"markdown","metadata":{},"source":["**preprocess images**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:04.782705Z","iopub.status.busy":"2024-04-23T08:37:04.782322Z","iopub.status.idle":"2024-04-23T08:37:27.026596Z","shell.execute_reply":"2024-04-23T08:37:27.025299Z","shell.execute_reply.started":"2024-04-23T08:37:04.782671Z"},"trusted":true},"outputs":[],"source":["#load the image and convert to numpy array\n","train_images = [np.array(load_img(path)) for path in tqdm(image_paths)]\n","train_images = np.array(train_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:27.028830Z","iopub.status.busy":"2024-04-23T08:37:27.028466Z","iopub.status.idle":"2024-04-23T08:37:27.036585Z","shell.execute_reply":"2024-04-23T08:37:27.035292Z","shell.execute_reply.started":"2024-04-23T08:37:27.028800Z"},"trusted":true},"outputs":[],"source":["train_images[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:27.038980Z","iopub.status.busy":"2024-04-23T08:37:27.038322Z","iopub.status.idle":"2024-04-23T08:37:28.447345Z","shell.execute_reply":"2024-04-23T08:37:28.446009Z","shell.execute_reply.started":"2024-04-23T08:37:27.038945Z"},"trusted":true},"outputs":[],"source":["#reshape the images\n","# 64 ,64 => height X width\n","# 3 => RGB images . If greyscale images then 1\n","train_images = train_images.reshape(train_images.shape[0],64,64,3).astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:28.449246Z","iopub.status.busy":"2024-04-23T08:37:28.448824Z","iopub.status.idle":"2024-04-23T08:37:29.907201Z","shell.execute_reply":"2024-04-23T08:37:29.905934Z","shell.execute_reply.started":"2024-04-23T08:37:28.449176Z"},"trusted":true},"outputs":[],"source":["#normalize the image \n","# normally we normalize in range [0,1] but in GANs we have activation layer in tanh function which gives output in range [-1,-1]\n","train_images = (train_images - 127.5) / 127.5  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:29.910361Z","iopub.status.busy":"2024-04-23T08:37:29.908897Z","iopub.status.idle":"2024-04-23T08:37:29.920860Z","shell.execute_reply":"2024-04-23T08:37:29.919623Z","shell.execute_reply.started":"2024-04-23T08:37:29.910314Z"},"trusted":true},"outputs":[],"source":["train_images[0]"]},{"cell_type":"markdown","metadata":{},"source":["**Create Generator and Discriminator Models**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:29.926240Z","iopub.status.busy":"2024-04-23T08:37:29.925410Z","iopub.status.idle":"2024-04-23T08:37:29.932673Z","shell.execute_reply":"2024-04-23T08:37:29.931393Z","shell.execute_reply.started":"2024-04-23T08:37:29.926180Z"},"trusted":true},"outputs":[],"source":["#latent dimension for random noise\n","LATENT_DIM = 128 #based on latent dimension specified we generate variety in images.More the latent noise more is the variety of images\n","#weight initilizer\n","WEIGHT_INIT = keras.initializers.RandomNormal(mean = 0.0, stddev =0.02)\n","#no of channels of the image\n","CHANNELS=3"]},{"cell_type":"markdown","metadata":{},"source":["**Generator Model**\n","\n","this will create new images similar to training data from random noise"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:29.934593Z","iopub.status.busy":"2024-04-23T08:37:29.934173Z","iopub.status.idle":"2024-04-23T08:37:30.217745Z","shell.execute_reply":"2024-04-23T08:37:30.216321Z","shell.execute_reply.started":"2024-04-23T08:37:29.934552Z"},"trusted":true},"outputs":[],"source":["model = Sequential(name='generator')\n","#id random noise\n","model.add(layers.Dense(8*8*512,input_dim = LATENT_DIM))\n","model.add(layers.ReLU())\n","\n","#convert id to 3d\n","\n","model.add(layers.Reshape((8,8,512)))\n","\n","#upsample to 16x16\n","model.add(layers.Conv2DTranspose(256,(4,4),strides=(2,2), padding='same', kernel_initializer=WEIGHT_INIT))\n","model.add(layers.BatchNormalization())\n","model.add(layers.ReLU())\n","\n","#upsample to 32x32\n","model.add(layers.Conv2DTranspose(128,(4,4),strides=(2,2), padding='same', kernel_initializer=WEIGHT_INIT))\n","model.add(layers.BatchNormalization())\n","model.add(layers.ReLU())\n","\n","#upsample to 64x64\n","model.add(layers.Conv2DTranspose(64,(4,4),strides=(2,2), padding='same', kernel_initializer=WEIGHT_INIT))\n","model.add(layers.BatchNormalization())\n","model.add(layers.ReLU())\n","\n","model.add(layers.Conv2D(CHANNELS,(4,4),padding='same',activation='tanh'))\n","\n","generator = model\n","generator.summary()"]},{"cell_type":"markdown","metadata":{},"source":["**Discriminator Model**\n","\n","this will classify images from generator as real or fake"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:30.219825Z","iopub.status.busy":"2024-04-23T08:37:30.219416Z","iopub.status.idle":"2024-04-23T08:37:30.427779Z","shell.execute_reply":"2024-04-23T08:37:30.426522Z","shell.execute_reply.started":"2024-04-23T08:37:30.219792Z"},"trusted":true},"outputs":[],"source":["model = Sequential(name = 'discriminator')\n","input_shape = (64,64,3)\n","alpha = 0.2\n","\n","#create conv layers\n","model.add(layers.Conv2D(64,(4,4),strides=(2,2),padding='same',input_shape=input_shape))\n","model.add(layers.BatchNormalization())\n","model.add(layers.LeakyReLU(alpha=alpha))\n","\n","model.add(layers.Conv2D(128,(4,4),strides=(2,2),padding='same',input_shape=input_shape))\n","model.add(layers.BatchNormalization())\n","model.add(layers.LeakyReLU(alpha=alpha))\n","\n","model.add(layers.Conv2D(128,(4,4),strides=(2,2),padding='same',input_shape=input_shape))\n","model.add(layers.BatchNormalization())\n","model.add(layers.LeakyReLU(alpha=alpha))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dropout(0.4))\n","\n","#we are creating a linient discriminator so that the generator can be trained \n","\n","#output\n","model.add(layers.Dense(1,activation='sigmoid'))\n","\n","discriminator = model\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{},"source":["**Create Deep Convolutional GAN**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:30.429663Z","iopub.status.busy":"2024-04-23T08:37:30.429322Z","iopub.status.idle":"2024-04-23T08:37:30.449928Z","shell.execute_reply":"2024-04-23T08:37:30.448539Z","shell.execute_reply.started":"2024-04-23T08:37:30.429634Z"},"trusted":true},"outputs":[],"source":["class DCGAN(keras.Model):\n","    def __init__(self,generator,discriminator,latent_dim):\n","        super().__init__()\n","        self.generator= generator\n","        self.discriminator = discriminator\n","        self.latent_dim=latent_dim\n","        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n","        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n","     \n","    \n","    @property \n","    def metrics(self):\n","        return[self.g_loss_metric,self.d_loss_metric]\n","        \n","    def compile(self,g_optimizer,d_optimizer,loss_fn):\n","        super(DCGAN,self).compile()\n","        self.g_optimizer = g_optimizer\n","        self.d_optimizer = d_optimizer\n","        self.loss_fn = loss_fn\n","        \n","    def train_step(self, real_images):\n","        batch_size = tf.shape(real_images)[0]\n","        #generate random noise\n","        random_noise = tf.random.normal(shape=(batch_size,self.latent_dim))\n","        \n","        #train the discriminator with real(1) and fake(0) images\n","        \n","        with tf.GradientTape() as tape:\n","            #compute loss on real images\n","            pred_real = self.discriminator(real_images,training=True) #we are passing real_images into discriminator and it is predicting if images are real or not\n","            #generate real images\n","            real_labels = tf.ones((batch_size,1)) #labeling the real images with 1\n","            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels)) #label smoothing \n","            d_loss_real = self.loss_fn(real_labels,pred_real)\n","            \n","            #compute loss on fake images\n","            fake_images = self.generator(random_noise)\n","            pred_fake = self.discriminator(fake_images,training=True)\n","            #generate fake labels\n","            fake_labels = tf.zeros(batch_size,1)\n","            d_loss_fake = self.loss_fn(fake_labels,pred_fake)\n","            \n","            #total discriminator loss\n","            d_loss = (d_loss_real + d_loss_fake)/2 #ususlly we don't get loss like this, we are doing this here because we are customizing generator and discriminator models\n","            \n","        #compute discriminator gradients\n","        gradients = tape.gradient(d_loss , self.discriminator.trainable_variables)\n","        #update the gradients\n","        self.d_optimizer.apply_gradients(zip(gradients,self.discriminator.trainable_variables))\n","            \n","        #train the generator model\n","        labels = tf.ones((batch_size,1)) \n","        #generator want discriminator to think that fake images are real\n","        with tf.GradientTape() as tape:\n","                #generate fake images from generator\n","                fake_images = self.generator(random_noise, training = True)\n","                #classify images as real or fake\n","                pred_fake = self.discriminator(fake_images , training = True)\n","                #compute loss\n","                g_loss = self.loss_fn(labels, pred_fake)\n","               \n","        #compute gradients\n","        gradients = tape.gradient(g_loss,self.generator.trainable_variables)\n","        #update the gradients \n","        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n","            \n","        #update states for both models\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","            \n","        return{'d_loss': self.d_loss_metric.result(),'g_loss': self.g_loss_metric.result()}\n","            \n","            \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:30.452243Z","iopub.status.busy":"2024-04-23T08:37:30.451791Z","iopub.status.idle":"2024-04-23T08:37:30.469448Z","shell.execute_reply":"2024-04-23T08:37:30.468063Z","shell.execute_reply.started":"2024-04-23T08:37:30.452190Z"},"trusted":true},"outputs":[],"source":["class DCGANMonitor(keras.callbacks.Callback):\n","    def __init__(self,num_imgs=15,latent_dim=100):\n","        self.num_imgs = num_imgs\n","        self.latent_dim = latent_dim\n","        #create random noise for generating images\n","        self.noise = tf.random.normal([25,latent_dim]) #25-> 5*5 images in total\n","        \n","    def on_epoch_end(self, epoch , logs=None ): #after each epoch do this\n","        g_img = self.model.generator(self.noise) #generate image from noise\n","        #denormalize the image\n","        g_img = (g_img * 127.5) + 127.5 #aim to have a result in range [-1,1]\n","        g_img.numpy()\n","        \n","        \n","        fig = plt.figure(figsize=(8,8))  \n","        for i in range(self.num_imgs):\n","            plt.subplot(5,5,i+1)\n","            img = array_to_img(g_img[i])\n","            plt.imshow(img)\n","            plt.axis('off')\n","            \n","        plt.show()\n","        \n","    def on_train_end(self,logs=None):\n","        self.model.generator.save('generator.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:30.471740Z","iopub.status.busy":"2024-04-23T08:37:30.471353Z","iopub.status.idle":"2024-04-23T08:37:30.495114Z","shell.execute_reply":"2024-04-23T08:37:30.493470Z","shell.execute_reply.started":"2024-04-23T08:37:30.471709Z"},"trusted":true},"outputs":[],"source":["dcgan = DCGAN(generator=generator,discriminator=discriminator,latent_dim=LATENT_DIM)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:30.497613Z","iopub.status.busy":"2024-04-23T08:37:30.497171Z","iopub.status.idle":"2024-04-23T08:37:30.514317Z","shell.execute_reply":"2024-04-23T08:37:30.513274Z","shell.execute_reply.started":"2024-04-23T08:37:30.497579Z"},"trusted":true},"outputs":[],"source":["D_LR = 0.0001\n","G_LR = 0.0003\n","dcgan.compile(g_optimizer=Adam(learning_rate=G_LR,beta_1=0.5), d_optimizer=Adam(learning_rate=D_LR, beta_1=0.5), loss_fn=BinaryCrossentropy())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:37:30.517412Z","iopub.status.busy":"2024-04-23T08:37:30.516053Z","iopub.status.idle":"2024-04-23T09:05:22.923017Z","shell.execute_reply":"2024-04-23T09:05:22.921255Z","shell.execute_reply.started":"2024-04-23T08:37:30.517368Z"},"trusted":true},"outputs":[],"source":["N_EPOCHS = 50\n","dcgan.fit(train_images,epochs=N_EPOCHS, callbacks=[DCGANMonitor()])"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":195056,"sourceId":432296,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
